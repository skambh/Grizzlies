{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grizzlies import print_hello, Grizzlies, read_csv, read_json, read_excel, read_parquet, DataFrame, Series\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world!\n"
     ]
    }
   ],
   "source": [
    "print_hello()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.12.9, pytest-8.3.4, pluggy-1.5.0\n",
      "rootdir: /Users/shash/Documents/Classes/WN25/CSE584/Grizzlies\n",
      "configfile: pyproject.toml\n",
      "collected 12 items                                                             \u001b[0m\n",
      "\n",
      "test_basic.py \u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                               [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m________________________________ test_read_csv _________________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_read_csv\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        df = gr.read_csv(data_csv)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(df, gr.Grizzlies), \u001b[33m\"\u001b[39;49;00m\u001b[33mread_csv() should return a Grizzlies object\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(df, pd.DataFrame), \u001b[33m\"\u001b[39;49;00m\u001b[33mGrizzlies should inherit from pandas.DataFrame\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: Grizzlies should inherit from pandas.DataFrame\u001b[0m\n",
      "\u001b[1m\u001b[31mE       assert False\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where False = isinstance(    Duration          Date  Pulse  Maxpulse  Calories\\n0         60  '2020/12/01'    110       130     409.1\\n1         ...2     280.0\\n30        60  '2020/12/30'    102       129     380.3\\n31        60  '2020/12/31'     92       115     243.0, <class 'pandas.core.frame.DataFrame'>)\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +    where <class 'pandas.core.frame.DataFrame'> = pd.DataFrame\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_basic.py\u001b[0m:12: AssertionError\n",
      "\u001b[31m\u001b[1m________________________________ test_read_json ________________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_read_json\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      ">       df = gr.read_json(data_json)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_basic.py\u001b[0m:15: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/grizzlies/Grizzlies.py\u001b[0m:125: in read_json\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m Grizzlies(pd.read_json(*args, **kwargs))\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/io/json/_json.py\u001b[0m:791: in read_json\n",
      "    \u001b[0mjson_reader = JsonReader(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/io/json/_json.py\u001b[0m:904: in __init__\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m._get_data_from_filepath(filepath_or_buffer)\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <pandas.io.json._json.JsonReader object at 0x105db8740>\n",
      "filepath_or_buffer = 'data/data.json'\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m_get_data_from_filepath\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, filepath_or_buffer):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    The function read_json accepts three input types:\u001b[39;49;00m\n",
      "    \u001b[33m        1. filepath (string-like)\u001b[39;49;00m\n",
      "    \u001b[33m        2. file-like object (e.g. open file object, StringIO)\u001b[39;49;00m\n",
      "    \u001b[33m        3. JSON string\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    This method turns (1) into (2) to simplify the rest of the processing.\u001b[39;49;00m\n",
      "    \u001b[33m    It returns input types (2) and (3) unchanged.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    It raises FileNotFoundError if the input is a string ending in\u001b[39;49;00m\n",
      "    \u001b[33m    one of .json, .json.gz, .json.bz2, etc. but no such file exists.\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# if it is a string but the file does not exist, it might be a JSON string\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        filepath_or_buffer = stringify_path(filepath_or_buffer)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m (\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(filepath_or_buffer, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[95mor\u001b[39;49;00m is_url(filepath_or_buffer)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[95mor\u001b[39;49;00m is_fsspec_url(filepath_or_buffer)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[95mor\u001b[39;49;00m file_exists(filepath_or_buffer)\u001b[90m\u001b[39;49;00m\n",
      "        ):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mself\u001b[39;49;00m.handles = get_handle(\u001b[90m\u001b[39;49;00m\n",
      "                filepath_or_buffer,\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                encoding=\u001b[96mself\u001b[39;49;00m.encoding,\u001b[90m\u001b[39;49;00m\n",
      "                compression=\u001b[96mself\u001b[39;49;00m.compression,\u001b[90m\u001b[39;49;00m\n",
      "                storage_options=\u001b[96mself\u001b[39;49;00m.storage_options,\u001b[90m\u001b[39;49;00m\n",
      "                errors=\u001b[96mself\u001b[39;49;00m.encoding_errors,\u001b[90m\u001b[39;49;00m\n",
      "            )\u001b[90m\u001b[39;49;00m\n",
      "            filepath_or_buffer = \u001b[96mself\u001b[39;49;00m.handles.handle\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m (\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96misinstance\u001b[39;49;00m(filepath_or_buffer, \u001b[96mstr\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[95mand\u001b[39;49;00m filepath_or_buffer.lower().endswith(\u001b[90m\u001b[39;49;00m\n",
      "                (\u001b[33m\"\u001b[39;49;00m\u001b[33m.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,) + \u001b[96mtuple\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m.json\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mc\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[94mfor\u001b[39;49;00m c \u001b[95min\u001b[39;49;00m extension_to_compression)\u001b[90m\u001b[39;49;00m\n",
      "            )\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[95mand\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m file_exists(filepath_or_buffer)\u001b[90m\u001b[39;49;00m\n",
      "        ):\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mraise\u001b[39;49;00m \u001b[96mFileNotFoundError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mFile \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfilepath_or_buffer\u001b[33m}\u001b[39;49;00m\u001b[33m does not exist\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           FileNotFoundError: File data/data.json does not exist\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/io/json/_json.py\u001b[0m:960: FileNotFoundError\n",
      "\u001b[31m\u001b[1m________________________________ test_indexing _________________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_indexing\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        df = gr.read_csv(data_csv)\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m df.iloc[\u001b[94m0\u001b[39;49;00m] \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33miloc should return a row\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: 'method' object is not subscriptable\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_basic.py\u001b[0m:25: TypeError\n",
      "\u001b[31m\u001b[1m__________________________________ test_mean ___________________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_mean\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        df = gr.read_csv(data_csv)\u001b[90m\u001b[39;49;00m\n",
      ">       means = df.mean()\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_basic.py\u001b[0m:61: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/grizzlies/Grizzlies.py\u001b[0m:46: in mean\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._df.mean(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m:11693: in mean\n",
      "    \u001b[0mresult = \u001b[96msuper\u001b[39;49;00m().mean(axis, skipna, numeric_only, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m:12420: in mean\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._stat_function(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m:12377: in _stat_function\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._reduce(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m:11562: in _reduce\n",
      "    \u001b[0mres = df._mgr.reduce(blk_func)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/internals/managers.py\u001b[0m:1500: in reduce\n",
      "    \u001b[0mnbs = blk.reduce(func)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/internals/blocks.py\u001b[0m:404: in reduce\n",
      "    \u001b[0mresult = func(\u001b[96mself\u001b[39;49;00m.values)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m:11481: in blk_func\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m op(values, axis=axis, skipna=skipna, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/nanops.py\u001b[0m:147: in f\n",
      "    \u001b[0mresult = alt(values, axis=axis, skipna=skipna, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/nanops.py\u001b[0m:404: in new_func\n",
      "    \u001b[0mresult = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/nanops.py\u001b[0m:719: in nanmean\n",
      "    \u001b[0mthe_sum = values.sum(axis, dtype=dtype_sum)\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "a = array([[\"'2020/12/01'\", \"'2020/12/02'\", \"'2020/12/03'\", \"'2020/12/04'\",\n",
      "        \"'2020/12/05'\", \"'2020/12/06'\", \"'2020...0201226', \"'2020/12/27'\",\n",
      "        \"'2020/12/28'\", \"'2020/12/29'\", \"'2020/12/30'\", \"'2020/12/31'\"]],\n",
      "      dtype=object)\n",
      "axis = 1, dtype = dtype('O'), out = None, keepdims = False, initial = <no value>\n",
      "where = True\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m_sum\u001b[39;49;00m(a, axis=\u001b[94mNone\u001b[39;49;00m, dtype=\u001b[94mNone\u001b[39;49;00m, out=\u001b[94mNone\u001b[39;49;00m, keepdims=\u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "             initial=_NoValue, where=\u001b[94mTrue\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       TypeError: can only concatenate str (not \"int\") to str\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/numpy/_core/_methods.py\u001b[0m:52: TypeError\n",
      "\u001b[31m\u001b[1m__________________________________ test_merge __________________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_merge\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        df1 = gr.read_csv(data_csv)\u001b[90m\u001b[39;49;00m\n",
      "        df2 = gr.read_csv(data_csv)\u001b[90m\u001b[39;49;00m\n",
      ">       merged = df1.merge(df2, on=df.columns[\u001b[94m0\u001b[39;49;00m], how=\u001b[33m\"\u001b[39;49;00m\u001b[33minner\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       NameError: name 'df' is not defined\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_basic.py\u001b[0m:67: NameError\n",
      "\u001b[31m\u001b[1m_________________________________ test_groupby _________________________________\u001b[0m\n",
      "\n",
      "self = <pandas.core.groupby.generic.DataFrameGroupBy object at 0x108f1ea20>\n",
      "how = 'mean'\n",
      "values = array([[\"'2020/12/01'\", \"'2020/12/02'\", \"'2020/12/03'\", \"'2020/12/04'\",\n",
      "        \"'2020/12/05'\", \"'2020/12/06'\", \"'2020...0201226', \"'2020/12/27'\",\n",
      "        \"'2020/12/28'\", \"'2020/12/29'\", \"'2020/12/30'\", \"'2020/12/31'\"]],\n",
      "      dtype=object)\n",
      "ndim = 2, alt = <function GroupBy.mean.<locals>.<lambda> at 0x108f79e40>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m_agg_py_fallback\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m, how: \u001b[96mstr\u001b[39;49;00m, values: ArrayLike, ndim: \u001b[96mint\u001b[39;49;00m, alt: Callable\u001b[90m\u001b[39;49;00m\n",
      "    ) -> ArrayLike:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Fallback to pure-python aggregation if _cython_operation raises\u001b[39;49;00m\n",
      "    \u001b[33m    NotImplementedError.\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# We get here with a) EADtypes and b) object dtype\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m alt \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m values.ndim == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# For DataFrameGroupBy we only get here with ExtensionArray\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            ser = Series(values, copy=\u001b[94mFalse\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# We only get here with values.dtype == object\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            df = DataFrame(values.T, dtype=values.dtype)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# bc we split object blocks in grouped_reduce, we have only 1 col\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# otherwise we'd have to worry about block-splitting GH#39329\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m df.shape[\u001b[94m1\u001b[39;49;00m] == \u001b[94m1\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Avoid call to self.values that can occur in DataFrame\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m#  reductions; see GH#28949\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            ser = df.iloc[:, \u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# We do not get here with UDFs, so we know that our dtype\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#  should always be preserved by the implemented aggregations\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# TODO: Is this exactly right; see WrappedCythonOp get_result_dtype?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">           res_values = \u001b[96mself\u001b[39;49;00m._grouper.agg_series(ser, alt, preserve_dtype=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/groupby/groupby.py\u001b[0m:1942: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/groupby/ops.py\u001b[0m:864: in agg_series\n",
      "    \u001b[0mresult = \u001b[96mself\u001b[39;49;00m._aggregate_series_pure_python(obj, func)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/groupby/ops.py\u001b[0m:885: in _aggregate_series_pure_python\n",
      "    \u001b[0mres = func(group)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/groupby/groupby.py\u001b[0m:2454: in <lambda>\n",
      "    \u001b[0malt=\u001b[94mlambda\u001b[39;49;00m x: Series(x, copy=\u001b[94mFalse\u001b[39;49;00m).mean(numeric_only=numeric_only),\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/series.py\u001b[0m:6549: in mean\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m NDFrame.mean(\u001b[96mself\u001b[39;49;00m, axis, skipna, numeric_only, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m:12420: in mean\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._stat_function(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m:12377: in _stat_function\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._reduce(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/series.py\u001b[0m:6457: in _reduce\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m op(delegate, skipna=skipna, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/nanops.py\u001b[0m:147: in f\n",
      "    \u001b[0mresult = alt(values, axis=axis, skipna=skipna, **kwds)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/nanops.py\u001b[0m:404: in new_func\n",
      "    \u001b[0mresult = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/nanops.py\u001b[0m:720: in nanmean\n",
      "    \u001b[0mthe_sum = _ensure_numeric(the_sum)\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "x = \"'2020/12/09'\"\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m_ensure_numeric\u001b[39;49;00m(x):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(x, np.ndarray):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m x.dtype.kind \u001b[95min\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mbiu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                x = x.astype(np.float64)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melif\u001b[39;49;00m x.dtype == \u001b[96mobject\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                inferred = lib.infer_dtype(x)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m inferred \u001b[95min\u001b[39;49;00m [\u001b[33m\"\u001b[39;49;00m\u001b[33mstring\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mmixed\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[90m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mraise\u001b[39;49;00m \u001b[96mTypeError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mCould not convert \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mx\u001b[33m}\u001b[39;49;00m\u001b[33m to numeric\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    x = x.astype(np.complex128)\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mexcept\u001b[39;49;00m (\u001b[96mTypeError\u001b[39;49;00m, \u001b[96mValueError\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                        x = x.astype(np.float64)\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mexcept\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m \u001b[94mas\u001b[39;49;00m err:\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[90m# GH#29941 we get here with object arrays containing strs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                        \u001b[94mraise\u001b[39;49;00m \u001b[96mTypeError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mCould not convert \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mx\u001b[33m}\u001b[39;49;00m\u001b[33m to numeric\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96merr\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m np.any(np.imag(x)):\u001b[90m\u001b[39;49;00m\n",
      "                        x = x.real\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m (is_float(x) \u001b[95mor\u001b[39;49;00m is_integer(x) \u001b[95mor\u001b[39;49;00m is_complex(x)):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(x, \u001b[96mstr\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">               \u001b[94mraise\u001b[39;49;00m \u001b[96mTypeError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mCould not convert string \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mx\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m to numeric\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE               TypeError: Could not convert string ''2020/12/09'' to numeric\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/nanops.py\u001b[0m:1701: TypeError\n",
      "\n",
      "\u001b[33mThe above exception was the direct cause of the following exception:\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_groupby\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        df = gr.read_csv(data_csv)\u001b[90m\u001b[39;49;00m\n",
      ">       grouped = df.groupby(df.columns[\u001b[94m0\u001b[39;49;00m]).mean()\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_basic.py\u001b[0m:72: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/groupby/groupby.py\u001b[0m:2452: in mean\n",
      "    \u001b[0mresult = \u001b[96mself\u001b[39;49;00m._cython_agg_general(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/groupby/groupby.py\u001b[0m:1998: in _cython_agg_general\n",
      "    \u001b[0mnew_mgr = data.grouped_reduce(array_func)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/internals/managers.py\u001b[0m:1469: in grouped_reduce\n",
      "    \u001b[0mapplied = sb.apply(func)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/internals/blocks.py\u001b[0m:393: in apply\n",
      "    \u001b[0mresult = func(\u001b[96mself\u001b[39;49;00m.values, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/groupby/groupby.py\u001b[0m:1995: in array_func\n",
      "    \u001b[0mresult = \u001b[96mself\u001b[39;49;00m._agg_py_fallback(how, values, ndim=data.ndim, alt=alt)\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <pandas.core.groupby.generic.DataFrameGroupBy object at 0x108f1ea20>\n",
      "how = 'mean'\n",
      "values = array([[\"'2020/12/01'\", \"'2020/12/02'\", \"'2020/12/03'\", \"'2020/12/04'\",\n",
      "        \"'2020/12/05'\", \"'2020/12/06'\", \"'2020...0201226', \"'2020/12/27'\",\n",
      "        \"'2020/12/28'\", \"'2020/12/29'\", \"'2020/12/30'\", \"'2020/12/31'\"]],\n",
      "      dtype=object)\n",
      "ndim = 2, alt = <function GroupBy.mean.<locals>.<lambda> at 0x108f79e40>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92m_agg_py_fallback\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m, how: \u001b[96mstr\u001b[39;49;00m, values: ArrayLike, ndim: \u001b[96mint\u001b[39;49;00m, alt: Callable\u001b[90m\u001b[39;49;00m\n",
      "    ) -> ArrayLike:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Fallback to pure-python aggregation if _cython_operation raises\u001b[39;49;00m\n",
      "    \u001b[33m    NotImplementedError.\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# We get here with a) EADtypes and b) object dtype\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m alt \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m values.ndim == \u001b[94m1\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# For DataFrameGroupBy we only get here with ExtensionArray\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            ser = Series(values, copy=\u001b[94mFalse\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# We only get here with values.dtype == object\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            df = DataFrame(values.T, dtype=values.dtype)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# bc we split object blocks in grouped_reduce, we have only 1 col\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# otherwise we'd have to worry about block-splitting GH#39329\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94massert\u001b[39;49;00m df.shape[\u001b[94m1\u001b[39;49;00m] == \u001b[94m1\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Avoid call to self.values that can occur in DataFrame\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m#  reductions; see GH#28949\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            ser = df.iloc[:, \u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# We do not get here with UDFs, so we know that our dtype\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m#  should always be preserved by the implemented aggregations\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# TODO: Is this exactly right; see WrappedCythonOp get_result_dtype?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            res_values = \u001b[96mself\u001b[39;49;00m._grouper.agg_series(ser, alt, preserve_dtype=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mexcept\u001b[39;49;00m \u001b[96mException\u001b[39;49;00m \u001b[94mas\u001b[39;49;00m err:\u001b[90m\u001b[39;49;00m\n",
      "            msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33magg function failed [how->\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mhow\u001b[33m}\u001b[39;49;00m\u001b[33m,dtype->\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mser.dtype\u001b[33m}\u001b[39;49;00m\u001b[33m]\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# preserve the kind of exception that raised\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mraise\u001b[39;49;00m \u001b[96mtype\u001b[39;49;00m(err)(msg) \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[04m\u001b[96merr\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           TypeError: agg function failed [how->mean,dtype->object]\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/Users/shash/anaconda3/envs/cse584/lib/python3.12/site-packages/pandas/core/groupby/groupby.py\u001b[0m:1946: TypeError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m test_basic.py::\u001b[1mtest_read_csv\u001b[0m - AssertionError: Grizzlies should inherit from pandas.DataFrame\n",
      "\u001b[31mFAILED\u001b[0m test_basic.py::\u001b[1mtest_read_json\u001b[0m - FileNotFoundError: File data/data.json does not exist\n",
      "\u001b[31mFAILED\u001b[0m test_basic.py::\u001b[1mtest_indexing\u001b[0m - TypeError: 'method' object is not subscriptable\n",
      "\u001b[31mFAILED\u001b[0m test_basic.py::\u001b[1mtest_mean\u001b[0m - TypeError: can only concatenate str (not \"int\") to str\n",
      "\u001b[31mFAILED\u001b[0m test_basic.py::\u001b[1mtest_merge\u001b[0m - NameError: name 'df' is not defined\n",
      "\u001b[31mFAILED\u001b[0m test_basic.py::\u001b[1mtest_groupby\u001b[0m - TypeError: agg function failed [how->mean,dtype->object]\n",
      "\u001b[31m========================= \u001b[31m\u001b[1m6 failed\u001b[0m, \u001b[32m6 passed\u001b[0m\u001b[31m in 0.51s\u001b[0m\u001b[31m ==========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_basic.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse584",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
